{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripAdvisor Recommendation System\n",
    "\n",
    "In this project, we aim to develop a recommendation system for TripAdvisor reviews that surpasses the performance of the BM25 algorithm. We'll begin by implementing a BM25 baseline using the `rank_bm25` library and then explore advanced Natural Language Processing (NLP) techniques to enhance the recommendation system.\n",
    "\n",
    "## 1. Data Preparation\n",
    "\n",
    "### 1.1 Importing Necessary Libraries\n",
    "\n",
    "We'll start by importing the essential libraries for data manipulation and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading the Dataset\n",
    "\n",
    "Next, we'll load the TripAdvisor Hotel Reviews dataset. Ensure that the dataset file (`Reviews.csv`) is in the same directory as this notebook or provide the correct path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('tripadvisor_hotel_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Rating'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Inspecting the Dataset\n",
    "\n",
    "Let's examine the first few rows of the dataset to understand its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should have the following columns:\n",
    "\n",
    "- `Review`: Concatenated reviews for the place.\n",
    "- `Rating`: Average rating of the place based on all reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preprocessing the Reviews\n",
    "\n",
    "We'll preprocess the concatenated reviews by tokenizing the text, converting it to lowercase, removing punctuation, and eliminating stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove punctuation and stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the reviews\n",
    "df['processed_review'] = df['Review'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing the BM25 Baseline\n",
    "\n",
    "### 2.1 Installing the `rank_bm25` Library\n",
    "\n",
    "We'll install the `rank_bm25` library, which provides an efficient implementation of the BM25 algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rank_bm25) (1.26.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Initializing the BM25 Model\n",
    "\n",
    "We'll initialize the BM25 model with the processed reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Create a list of processed reviews\n",
    "corpus = df['processed_review'].tolist()\n",
    "\n",
    "# Initialize the BM25 model\n",
    "bm25 = BM25Okapi(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Defining a Function to Recommend Similar Places\n",
    "\n",
    "We'll define a function that, given a place's index, returns the most similar place based on BM25 similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_place(index):\n",
    "    # Get the processed review of the place\n",
    "    query = df.loc[index, 'processed_review']\n",
    "    # Compute BM25 scores\n",
    "    scores = bm25.get_scores(query)\n",
    "    # Get the index of the most similar place (excluding the query place itself)\n",
    "    scores[index] = -float('inf')  # Exclude the same place\n",
    "    most_similar_index = scores.argmax()\n",
    "    return most_similar_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluating the BM25 Model\n",
    "\n",
    "To evaluate the effectiveness of the BM25 model, we'll calculate the Mean Squared Error (MSE) between the average ratings of each place and the ratings of its most similar recommended place. This comparison allows us to assess how accurately BM25 matches each place with another based on review similarity, without using any explicit rating information.\n",
    "\n",
    "We'll optimize this process by using parallel processing with `joblib`, enabling us to compute the MSE across all entries in the dataset more efficiently. By leveraging all available CPU cores, this approach significantly reduces the time required to perform the evaluation on the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Average MSE for first 100 entries: 1.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# Select the first 5000 indexes\n",
    "sample_indexes = df.index[:100]\n",
    "\n",
    "def compute_mse_for_index(index):\n",
    "    # Get the recommended place\n",
    "    recommended_index = recommend_similar_place(index)\n",
    "    # Get the ratings of the query and recommended places\n",
    "    query_rating = df.loc[index, 'Rating']\n",
    "    recommended_rating = df.loc[recommended_index, 'Rating']\n",
    "    # Compute MSE for the current pair\n",
    "    return mean_squared_error([query_rating], [recommended_rating])\n",
    "\n",
    "def evaluate_bm25_parallel(selected_indexes):\n",
    "    # Use Parallel to compute the MSE in parallel for the selected indexes\n",
    "    mse_scores = Parallel(n_jobs=-1)(delayed(compute_mse_for_index)(index) for index in selected_indexes)\n",
    "    # Compute the average MSE\n",
    "    average_mse = np.mean(mse_scores)\n",
    "    return average_mse\n",
    "\n",
    "# Evaluate the BM25 model on the first 5000 entries\n",
    "bm25_mse = evaluate_bm25_parallel(sample_indexes)\n",
    "print(f'BM25 Average MSE for first 100 entries: {bm25_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Developing an Enhanced Recommendation Model\n",
    "\n",
    "To improve on the BM25 baseline, we'll use a hybrid approach by combining BM25 with word embeddings. The goal is to create a model that better captures the semantic similarities between reviews. Specifically, we'll:\n",
    "\n",
    "1. Generate embeddings for each review using a pre-trained model.\n",
    "2. Combine BM25 similarity scores with embedding-based similarity scores for improved recommendations.\n",
    "\n",
    "This hybrid approach should ideally reduce the Mean Squared Error (MSE) compared to BM25 alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setting Up Pre-trained Embeddings\n",
    "\n",
    "We'll start by generating sentence embeddings for each review using `Sentence-BERT`. These embeddings will help capture semantic similarities between reviews, which we can then combine with BM25 similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.0.1+cu117)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\anis\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Anis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each review in the dataset\n",
    "df['embedding'] = df['Review'].apply(lambda x: model.encode(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculating Similarity Scores\n",
    "\n",
    "We'll use cosine similarity between the embeddings to determine the semantic similarity between reviews. This similarity measure will complement the BM25 score, which is based on exact word matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_embedding_similarity(index, candidate_index):\n",
    "    # Retrieve the embeddings for both reviews\n",
    "    embedding1 = df.loc[index, 'embedding']\n",
    "    embedding2 = df.loc[candidate_index, 'embedding']\n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([embedding1], [embedding2])[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hybrid Recommendation Function\n",
    "\n",
    "We'll develop a hybrid recommendation function that combines BM25 and embedding similarities to find the most similar place. We’ll use a weighted average of BM25 and embedding scores to adjust their influence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid_place(index, alpha=0.5):\n",
    "    # Get the BM25 scores\n",
    "    query = df.loc[index, 'processed_review']\n",
    "    bm25_scores = bm25.get_scores(query)\n",
    "    \n",
    "    # Combine BM25 and embedding similarities for all other entries\n",
    "    hybrid_scores = []\n",
    "    for candidate_index in df.index:\n",
    "        if candidate_index != index:\n",
    "            # Get BM25 score\n",
    "            bm25_score = bm25_scores[candidate_index]\n",
    "            # Get embedding similarity\n",
    "            embedding_score = get_embedding_similarity(index, candidate_index)\n",
    "            # Hybrid score: weighted average of BM25 and embedding scores\n",
    "            hybrid_score = alpha * bm25_score + (1 - alpha) * embedding_score\n",
    "            hybrid_scores.append((candidate_index, hybrid_score))\n",
    "    \n",
    "    # Sort by hybrid score (higher is better) and return the best match\n",
    "    most_similar_index = max(hybrid_scores, key=lambda x: x[1])[0]\n",
    "    return most_similar_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Evaluating the Hybrid Model\n",
    "\n",
    "We'll evaluate the hybrid model on the first 100 entries and compare its Mean Squared Error (MSE) with that of BM25. This will help us assess if our modifications improve the recommendation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model Average MSE for first 100 entries: 1.48\n"
     ]
    }
   ],
   "source": [
    "def evaluate_hybrid_parallel(selected_indexes=None, alpha=0.5):\n",
    "    if selected_indexes is None:\n",
    "        selected_indexes = df.index[:100]  # Default to first 5000 entries if none specified\n",
    "    mse_scores = Parallel(n_jobs=8)(delayed(lambda idx: mean_squared_error(\n",
    "        [df.loc[idx, 'Rating']],\n",
    "        [df.loc[recommend_hybrid_place(idx, alpha), 'Rating']]\n",
    "    ))(index) for index in selected_indexes)\n",
    "    # Calculate average MSE\n",
    "    average_mse = np.mean(mse_scores)\n",
    "    return average_mse\n",
    "\n",
    "# Run evaluation with alpha set to 0.5 for equal weighting\n",
    "hybrid_mse = evaluate_hybrid_parallel(sample_indexes, alpha=0.2)\n",
    "print(f'Hybrid Model Average MSE for first 100 entries: {hybrid_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Analyzing the Hybrid Model Results\n",
    "\n",
    "After running the hybrid model that combines BM25 with embedding similarity, we got an MSE of 1.48, compared to the BM25-only baseline of 1.58. This improvement likely comes from adding the embeddings, which help capture the meaning of reviews more effectively than BM25 alone.\n",
    "\n",
    "#### Why the Hybrid Model Performed Better\n",
    "1. **Understanding Context**: Embeddings help pick up on the meaning of words, not just exact matches, so similar reviews are matched even if they use different words.\n",
    "2. **Balancing Exact and Semantic Similarity**: By mixing BM25’s exact word matching with the semantic similarity from embeddings, we get a better overall match between reviews.\n",
    "\n",
    "Overall, it looks like adding embeddings was worth it, as it reduced our MSE and improved the model's ability to identify similar reviews.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Trying Out Another Method: Word Mover's Distance (WMD)\n",
    "\n",
    "To keep exploring ways to improve the recommendation accuracy, we’re going to try out **Word Mover's Distance (WMD)**. WMD calculates the \"distance\" between two documents by finding the minimum \"cost\" to match words from one document to another based on their meaning.\n",
    "\n",
    "#### Why Try WMD?\n",
    "WMD uses word embeddings to measure the distance between two documents, capturing both word similarity and structure. This can help it find closer matches between reviews.\n",
    "\n",
    "### 4.1 Setting Up Word Mover's Distance Using Preprocessed Reviews\n",
    "\n",
    "We'll calculate WMD using the preprocessed, tokenized reviews we already created. We’ll load a pre-trained Word2Vec model to measure the distance between reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting POT"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading POT-0.9.5-cp311-cp311-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from POT) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6 in c:\\users\\anis\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from POT) (1.11.4)\n",
      "Downloading POT-0.9.5-cp311-cp311-win_amd64.whl (348 kB)\n",
      "   ---------------------------------------- 0.0/348.6 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 286.7/348.6 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 348.6/348.6 kB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: POT\n",
      "Successfully installed POT-0.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained Word2Vec model (for example purposes, using a smaller one)\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Implementing WMD for Recommendations\n",
    "\n",
    "Using WMD, we’ll find the most similar review to a given review by calculating the minimal \"distance\" in meaning between words in two reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_wmd_place(index):\n",
    "    query_review = df.loc[index, 'processed_review']\n",
    "    wmd_distances = []\n",
    "    \n",
    "    for candidate_index in df.index:\n",
    "        if candidate_index != index:\n",
    "            candidate_review = df.loc[candidate_index, 'processed_review']\n",
    "            # Compute Word Mover's Distance\n",
    "            wmd_distance = model.wmdistance(query_review, candidate_review)\n",
    "            wmd_distances.append((candidate_index, wmd_distance))\n",
    "    \n",
    "    # Sort by WMD (lower distance is better) and return the best match\n",
    "    most_similar_index = min(wmd_distances, key=lambda x: x[1])[0]\n",
    "    return most_similar_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluating the WMD-Based Model\n",
    "\n",
    "We’ll evaluate the WMD model on the first 100 entries by calculating the Mean Squared Error (MSE) between the ratings of each place and the closest place found by WMD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMD Model Average MSE for first 100 entries: 1.18\n"
     ]
    }
   ],
   "source": [
    "def evaluate_wmd_parallel(selected_indexes=None):\n",
    "    if selected_indexes is None:\n",
    "        selected_indexes = df.index[:100]  # Default to first 100 entries\n",
    "    mse_scores = Parallel(n_jobs=2)(delayed(lambda idx: mean_squared_error(\n",
    "        [df.loc[idx, 'Rating']],\n",
    "        [df.loc[recommend_wmd_place(idx), 'Rating']]\n",
    "    ))(index) for index in selected_indexes)\n",
    "    # Calculate average MSE\n",
    "    average_mse = np.mean(mse_scores)\n",
    "    return average_mse\n",
    "\n",
    "# Run evaluation on the first 100 entries\n",
    "wmd_mse = evaluate_wmd_parallel(sample_indexes)\n",
    "print(f'WMD Model Average MSE for first 100 entries: {wmd_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Comparing the Results of the Three Models\n",
    "\n",
    "After evaluating all three models on the first 100 entries of TripAdvisor hotel reviews, we observed the following Mean Squared Error (MSE) values:\n",
    "\n",
    "- **BM25 Baseline Model**: MSE = 1.58\n",
    "- **Hybrid Model (BM25 + Embeddings)**: MSE = 1.48\n",
    "- **Word Mover's Distance (WMD) Model**: MSE = 1.18\n",
    "\n",
    "#### How Each Model Works\n",
    "\n",
    "1. **BM25 Baseline Model**:\n",
    "   - BM25 is a popular improvement on TF-IDF that calculates relevance based on term frequency (TF) within documents and inverse document frequency (IDF) across the corpus.\n",
    "   - It also prefers shorter documents when two documents have similar TF-IDF scores.\n",
    "   - In this project, BM25 finds similar reviews by prioritizing exact word matches and frequency within the reviews, making it effective for identifying hotels with similar feedback based on specific terms (e.g., \"clean rooms\" or \"friendly staff\"). However, it lacks an understanding of word meaning, so it might not pick up on context if the language varies.\n",
    "\n",
    "2. **Hybrid Model (BM25 + Embeddings)**:\n",
    "   - This model combines BM25 scores with cosine similarity scores from Sentence-BERT embeddings, which provide vector-based representations that capture semantic relationships.\n",
    "   - Embeddings capture more contextual meaning, helping the model match reviews that discuss similar ideas even if they use different words (e.g., \"very clean\" vs. \"spotless\").\n",
    "   - The hybrid model uses a weighted average of BM25 and embedding similarity, controlled by the parameter `alpha` (set to 0.2 to emphasize embeddings more). \n",
    "   - By blending BM25’s exact matching with embedding-based semantic similarity, the hybrid model improved the MSE to 1.48, showing it could capture a bit more context than BM25 alone.\n",
    "\n",
    "3. **Word Mover's Distance (WMD) Model**:\n",
    "   - WMD calculates the “distance” between two documents by finding the minimal cumulative \"travel cost\" required to transform one document’s words into the other’s, using word embeddings.\n",
    "   - WMD doesn’t just rely on matches or weighted averages—it measures the actual \"distance\" in meaning between words, enabling it to find reviews that express similar sentiments in different ways.\n",
    "   - For hotel reviews, this means WMD can match reviews more effectively when similar experiences are described with varied language, helping it handle nuances in customer feedback.\n",
    "\n",
    "#### Why WMD Performed the Best\n",
    "\n",
    "WMD outperformed both BM25 and the hybrid model, achieving the lowest MSE of 1.18. This likely happened for several reasons:\n",
    "\n",
    "1. **Deeper Semantic Matching**: WMD can match reviews based on meaning rather than exact words. This means it can find reviews that are expressing similar feedback, even if the words used differ, which is useful for identifying hotels with similar guest experiences.\n",
    "   \n",
    "2. **Optimal Word Transport**: WMD calculates the minimum \"cost\" to match words between two reviews, capturing subtle similarities in word usage that BM25 and the hybrid model might miss.\n",
    "\n",
    "3. **Context-Aware Matching**: Unlike BM25, which is limited to exact word matches, and the hybrid model, which uses a blend of similarity scores, WMD adapts fully to the context of each pair of reviews, making it more flexible and effective at finding meaningful connections in the hotel review dataset.\n",
    "\n",
    "Overall, WMD’s ability to handle language variations and capture deeper semantic similarities likely contributed to its better performance on TripAdvisor reviews.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
